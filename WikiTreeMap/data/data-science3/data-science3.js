var dataScience3ItemList = [{"id":"Data Science","name":"Data Science 3","href":"#data-science","type":"","shortdescription":"","description":"Data Science is a process, not an event. It is the process of using data to understand different things, to understand the world. For me is when you have a model or hypothesis of a problem, and you try to validate that hypothesis or model with your data. Data science is the art of uncovering the insights and trends that are hiding behind data.","expanded":true,"children":[{"id":"Data Science.What is Data Science","name":"What is Data Science","href":"","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Tools for DataScience","name":"Tools for DataScience","href":"","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Tools for DataScience.Languages for DataScience","name":"Languages for DataScience","href":"","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Tools for DataScience.Languages for DataScience.Python","name":"Python","href":"#python","type":"","shortdescription":"","description":"1. Python is a high-level general-purpose programming language that can be applied to many different classes of problems. <br>2. It has a large, standard library that provides tools suited to many different tasks, including but not limited to databases, automation, web scraping, text processing, image processing, machine learning, and data analytics. <br>3. For data science, you can use Python's scientific computing libraries such as Pandas, NumPy, SciPy, and Matplotlib. <br>4. For artificial intelligence, it has TensorFlow, PyTorch, Keras, and Scikit-learn. <br>5. Python can also be used for Natural Language Processing (NLP) using the Natural Language Toolkit (NLTK)","children":[]},{"id":"Data Science.Tools for DataScience.Languages for DataScience.R","name":"R","href":"#r-language","type":"","shortdescription":"","description":"R is most often used by statisticians, mathematicians, and data miners for developing statistical software, graphing, and data analysis. The language’s array-oriented syntax makes it easier to translate from math to code.","children":[]}]},{"id":"Data Science.Tools for DataScience.Data Science Tools","name":"Data Science Tools","href":"#data-science-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.jpg />","children":[{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source","name":"Open Source","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Data Management","name":"Data Management Tools","href":"#data-management-tools","type":"","shortdescription":"","description":"Relational databases such as MySQL and PostgreSQL; NoSQL databases such as MongoDB Apache CouchDB, and Apache Cassandra; and file-based tools such as the Hadoop File System or Cloud File systems like Ceph. Elasticsearch is mainly used for storing text data and creating a search index for fast document retrieval.<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DataManagement.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Data Integration And Transformation","name":"Data Integration And Transformation","href":"#data-integration-and-transformation-tools","type":"","shortdescription":"","description":"Apache AirFlow, originally created by AirBNB; KubeFlow, which enables you to execute data science pipelines on top of Kubernetes; Apache Kafka, which originated from LinkedIn; Apache Nifi, which delivers a very nice visual editor; Apache SparkSQL (which enables you to use ANSI SQL and scales up to compute clusters of 1000s of nodes), and NodeRED, which also provides a visual editor. NodeRED consumes so little in resources that it even runs on small devices like a Raspberry Pi.<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DataIntegrationAndTransformation.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Data Visualization","name":"Data Visualization","href":"#data-visualization-tools","type":"","shortdescription":"","description":"Hue, which can create visualizations from SQL queries. Kibana, a data exploration and visualization web application, is limited to Elasticsearch (the data provider). Apache Superset is a data exploration and visualization web application.<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DataVisualization.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Model Deployment","name":"Model Deployment","href":"#model-deployment-tools","type":"","shortdescription":"","description":"Apache PredictionIO currently only supports Apache Spark ML models for deployment, but support for all sorts of other libraries is on the roadmap. Seldon is an interesting product since it supports nearly every framework, including TensorFlow, Apache SparkML, R, and scikit-learn. Seldon can run on top of Kubernetes and Redhat OpenShift. Another way to deploy SparkML models is by using MLeap. Finally, TensorFlow can serve any of its models using the TensorFlow service. You can deploy to an embedded device like a Raspberry Pi or a smartphone using TensorFlow Lite, and even deploy to a web browser using TensorFlow.JS. <img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.ModelDeployment.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Model Monitoring and Assessment","name":"Model Monitoring and Assessment","href":"#model-monitoring-and-assessment-tools","type":"","shortdescription":"","description":"ModelDB is a machine model metadatabase where information about the models are stored and can be queried. It natively supports Apache Spark ML Pipelines and scikit-learn. A generic, multi-purpose tool called Prometheus is also widely used for machine learning model monitoring, although it’s not specifically made for this purpose. Model performance is not exclusively measured through accuracy. Model bias against protected groups like gender or race is also important. The IBM AI Fairness 360 open source toolkit does exactly this. It detects and mitigates against bias in machine learning models. Machine learning models, especially neural-network-based deep learning models, can be subject to adversarial attacks, where an attacker tries to fool the model with manipulated data or by manipulating the model itself. The IBM Adversarial Robustness 360 Toolbox can be used to detect vulnerability to adversarial attacks and help make the model more robust. Machine learning modes are often considered to be a black box that applies some mysterious “magic.” The IBM AI Explainability 360 Toolkit makes the machine learning process more understandable by finding similar examples within a dataset that can be presented to a user for manual comparison. The IBM AI Explainability 360 Toolkit can also illustrate training for a simpler machine learning model by explaining how different input variables affect the final decision of the model. <img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.ModelMonitoringAndAssessment.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Code Asset Management","name":"Code Asset Management","href":"#code-asset-management-tools","type":"","shortdescription":"","description":"Git is now the standard. Multiple services have emerged to support Git, with the most prominent being GitHub, which provides hosting for software development version management. The runner-up is definitely GitLab, which has the advantage of being a fully open source platform that you can host and manage yourself. Another choice is Bitbucket. <img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.CostAssetManament.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Data Asset Management","name":"Data Asset Management","href":"#data-asset-management-tools","type":"","shortdescription":"","description":"Data asset management, also known as data governance or data lineage, is another crucial part of enterprise grade data science. Data has to be versioned and annotated with metadata. Apache Atlas is a tool that supports this task. Another interesting project, ODPi Egeria, is managed through the Linux Foundation and is an open ecosystem. It offers a set of open APIs, types, and interchange protocols that metadata repositories use to share and exchange data. Finally, Kylo is an open source data lake management software platform that provides extensive support for a wide range of data asset management tasks. <img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DataAssetManagement.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Development Environments","name":"Development Environments","href":"#development-environments-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DevelopmentEnvironments.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Execution Environments","name":"Execution Environments","href":"#execution-environments-tools","type":"","shortdescription":"","description":"Sometimes your data doesn’t fit into a single computer’s storage or main memory capacity. That’s where cluster execution environments come in. The well known cluster-computing framework Apache Spark is among the most active Apache projects and is used across all industries, including in many Fortune 500 companies. The key property of Apache Spark is linear scalability. This means, if you double the number of servers in a cluster, you’ll also roughly double its performance. After Apache Spark began to gain market share, Apache Flink was created. The key difference between Apache Spark and Apache Flink is that Apache Spark is a batch data processing engine, capable of processing huge amounts of data file by file. Apache Flink, on the other hand, is a stream processing image, with its main focus on processing real-time data streams. Although engine supports both data processing paradigms, Apache Spark is usually the choice in most use cases. One of the latest developments in the data science execution environments is called “Ray,” which has a clear focus on large-scale deep learning model training. <img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.ExecutionEnvironments.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Open Source.Fully Integrated Visual Tools","name":"Fully Integrated Visual Tools","href":"#fully-integrated-visual-tools","type":"","shortdescription":"","description":"Most important tasks are supported by these tools; these tasks include data integration, transformation, data visualization, and model building. KNIME originated at the University of Konstanz in 2004. As you can see, KNIME has a visual user interface with drag-and-drop capabilities. It also has built-in visualization capabilities. Knime can be be extended by programming in R and Python, and has connectors to Apache Spark. Another example of this group of tools is Orange. It’s less flexible than KNIME, but easier to use.<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.FullyIntegratedVisualTools.jpg /> ","children":[]}]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools","name":"Commercial Tools","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools.Data Management","name":"Data Management Commercial Tools","href":"#data-management-commercial-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DataManagementCommercial.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools.Data Integration And Transformation","name":"Data Integration And Transformation Commercial Tools","href":"#data-integration-and-transformation-commercial-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DataIntegrationAndTransformationCommercial.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools.Data Visualization","name":"Data Visualization Commercial Tools","href":"#data-visualization-commercial-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DataVisualizationCommercial.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools.Model Building Commercial","name":"Model Building Tools","href":"#model-building-commercial-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.ModelBuildingCommercial.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools.Model Deployment","name":"Model Deployment Commercial Tools","href":"#model-deployment-commercial-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.ModelDeploymentCommercial.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools.Data Asset Management","name":"Data Asset Management Commercial Tools","href":"#data-asset-management-commercial-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DataAssetManagementCommercial.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools.Development Environments","name":"Development Environments Commercial Tools","href":"#development-environments-commercial-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.DevelopmentEnvironments.jpg /> ","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools.Execution Environments","name":"Execution Environments Commercial Tools","href":"#execution-environments-commercial-tools","type":"","shortdescription":"","description":"IBM Watson Studio Desktop","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Commercial Tools.Fully Integrated Visual Tools","name":"Commercial Fully Integrated Visual Tools","href":"#fully-integrated-visual-commercial-tools","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.ToolsforDataScience.DataScienceTools.FullyIntegratedVisualToolsCommercial.jpg /> ","children":[]}]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Cloud Based Tools","name":"Cloud Based Tools","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Tools for DataScience.Data Science Tools.Cloud Based Tools.Fully Integrated Visual Tools and Platforms","name":"Cloud Based Fully Integrated Visual Tools","href":"#fully-integrated-visual-cloud-tools","type":"","shortdescription":"","description":"IBM Watson Studio<br>IBM Watson OpenScale<br>Azure Machine Learning<br>H2O Driverless AI","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Cloud Based Tools.Data Management","name":"Data Management Cloud Based Tools","href":"#data-management-cloud-tools","type":"","shortdescription":"","description":"Amazon DynamoDB<br>Cloudant<br>CouchDB relax<br>IBM Db2","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Cloud Based Tools.Data Integration And Transformation","name":"Data Integration And Transformation Cloud Based Tools","href":"#data-integration-and-transformation-cloud-tools","type":"","shortdescription":"","description":"Informatica<br>IBM Data Refinery","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Cloud Based Tools.Data Visualization","name":"Data Visualization Cloud Based Tools","href":"#data-visualization-cloud-tools","type":"","shortdescription":"","description":"Datameer<br>IBM Cognos Analytics<br>","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Cloud Based Tools.Model Building Cloud Based","name":"Model Building Tools","href":"#model-building-cloud-tools","type":"","shortdescription":"","description":"IBM Watson Machine Learning<br>Google AI Platform Training","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Cloud Based Tools.Model Deployment","name":"Model Deployment Cloud Based Tools","href":"#model-deployment-cloud-tools","type":"","shortdescription":"","description":"IBM SPSS Collaboration and Deployment Services<br>IBM Watson Machine Learning","children":[]},{"id":"Data Science.Tools for DataScience.Data Science Tools.Cloud Based Tools.Model Monitoring and Assessment","name":"Model Monitoring and Assessment Cloud Tools","href":"#model-monitoring-and-assessment-cloud-tools","type":"","shortdescription":"","description":"Amazon SageMaker Model Monitor<br>IBM Watson OpenScale","children":[]}]}]}]},{"id":"Data Science.Packages, APIs, Data Sets and Models","name":"Packages, APIs, Data Sets and Models","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries","name":"Libraries","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Scientifics Computing","name":"Scientifics Computing","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Scientifics Computing.Pandas (Data structures & tools)","name":"Pandas (Data structures & tools)","href":"#pandas","type":"","shortdescription":"","description":"Pandas offers data structures and tools for effective data cleaning, manipulation, and analysis. It provides tools to work with different types of data. The primary instrument of Pandas is a two-dimensional table consisting of columns and rows. This table is called a “DataFrame” and is designed to provide easy indexing so you can work with your data.","children":[]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Scientifics Computing.Numpy (Arrays & matrices)","name":"Numpy (Arrays & matrices)","href":"#numpy","type":"","shortdescription":"","description":"NumPy libraries are based on arrays, enabling you to apply mathematical functions to these arrays. Pandas is actually built on top of NumPy Data visualization methods are a great way to communicate with others and show the meaningful results of analysis.","children":[]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Scientifics Computing.SciPy (Integrals, solving differential equations, optimization)","name":"SciPy (Integrals, solving differential equations, optimization)","href":"#scipy","type":"","shortdescription":"","description":"SciPy includes functions for some advanced math problems as listed on this slide, as well as data visualization.","children":[]}]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Visualization","name":"Visualization","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Visualization.Matplotlib (plots & graphs, most popular)","name":"Matplotlib (plots & graphs, most popular)","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Visualization.Seaborn (plots: heat maps, time series, violin plots)","name":"Seaborn (plots: heat maps, time series, violin plots)","href":"#","type":"","shortdescription":"","description":"","children":[]}]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Machine Learning & Deep Learning","name":"Machine Learning & Deep Learning","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Machine Learning & Deep Learning.Scikit-learn (Machine Learning: regression, classification, )","name":"Scikit-learn (Machine Learning: regression, classification, )","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Machine Learning & Deep Learning.Statsmodels (Explore data, estimate statistical models and perform statistical tests)","name":"Statsmodels (Explore data, estimate statistical models and perform statistical tests)","href":"#","type":"","shortdescription":"","description":"","children":[]}]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Deep Learning Libraries","name":"Deep Learning Libraries","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Deep Learning Libraries.TensorFlow (Deep Learning: Production and Deployment)","name":"TensorFlow (Deep Learning: Production and Deployment)","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Libraries.Deep Learning Libraries.PyTorch (Deep Learning: regression, classification, )","name":"PyTorch (Deep Learning: regression, classification, )","href":"#","type":"","shortdescription":"","description":"","children":[]}]}]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Data Sets","name":"Data Sets","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Packages, APIs, Data Sets and Models.Data Sets.Open data","name":"Open data","href":"#open-data-where-to-find","type":"","shortdescription":"","description":"Where to find open data<br>Open data portal list from around the world<br>- http://datacatalogs.org/<br>Governmental, intergovernmental and organization websites<br>- http://data.un.org/ (United Nations)<br>- https://www.data.gov/ (USA)<br>- https://www.europeandataportal.eu/en/ (Europe)<br>Kaggle<br>- https://www.kaggle.com/datasets<br>Google data set search<br>- https://datasetsearch.research.google.com/","children":[]},{"id":"Data Science.Packages, APIs, Data Sets and Models.Data Sets.Community Data License Aggrement","name":"Community Data License Aggrement","href":"#cdla","type":"","shortdescription":"","description":"http://cdla.io","children":[]}]}]},{"id":"Data Science.Methodology","name":"Methodology","href":"#data-science-methodology","type":"","shortdescription":"","description":"1. From Problem to Approach <br>2. From Requirements to Collection <br>3. From Understanding to Preparation <br>4. From Modeling to Evaluation <br>5. From Deployment to Feedback<br><img src=assets/images/DataScience.Methodology.jpg />","children":[]},{"id":"Data Science.Data Analysis with Python","name":"Data Analysis with Python","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Data Analysis with Python.Importing Datasets","name":"Importing Datasets","href":"#importing-datasets","type":"","shortdescription":"","description":"<a href='pages/data-analysis/DA0101EN-Review-Introduction.ipynb' download>Download Sample Jupyter Notebook</a>","children":[]},{"id":"Data Science.Data Analysis with Python.Data Wrangling","name":"Data Wrangling","href":"#data-wrangling","type":"","shortdescription":"","description":"<a href='pages/data-analysis/DA0101EN-2-Review-Data-Wrangling.ipynb' download>Download Sample Jupyter Notebook</a>","children":[{"id":"Data Science.Data Analysis with Python.Data Wrangling.Missing values","name":"Missing values","href":"#missing-values","type":"","shortdescription":"","description":"Drop the missing values <br>- drop the variable<br>- drop the data entry<br><br>Replace the missing values<br>- replace with an average (of similar datapoints)<br>- replace by frequency<br>- replace based on other functions<br><br>Leave it as missing data","children":[]},{"id":"Data Science.Data Analysis with Python.Data Wrangling.Data Normalization","name":"Data Normalization","href":"#data-normalization","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.DataWrangling.DataNormalization.jpg />Normalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or scaling variable so the variable values range from 0 to 1","children":[{"id":"Data Science.Data Analysis with Python.Data Wrangling.Data Normalization.Simple Feature scaling","name":"Simple Feature scaling","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Data Analysis with Python.Data Wrangling.Data Normalization.Min-Max","name":"Min-Max","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Data Analysis with Python.Data Wrangling.Data Normalization.Z-score","name":"Z-score","href":"#","type":"","shortdescription":"","description":"","children":[]}]},{"id":"Data Science.Data Analysis with Python.Data Wrangling.Binning","name":"Binning","href":"#binning","type":"","shortdescription":"","description":"Grouping of values into \"bins\". Binning is a process of transforming continuous numerical variables into discrete categorical 'bins', for grouped analysis.<br><br>Example:<br>In our dataset, \"horsepower\" is a real valued variable ranging from 48 to 288, it has 57 unique values. What if we only care about the price difference between cars with high horsepower, medium horsepower, and little horsepower (3 types)? Can we rearrange them into three ‘bins' to simplify analysis?","children":[]},{"id":"Data Science.Data Analysis with Python.Data Wrangling.One-hot encoding","name":"One-hot encoding","href":"#one-hot-encoding","type":"","shortdescription":"","description":"Turn categorical variables into quantitative variables. <img src=assets/images/DataScience.DataAnalysiswithPython.DataWrangling.OneHotEncoding.jpg />","children":[]}]},{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis","name":"Exploratory Data Analysis","href":"#exploratory-data-analysis","type":"","shortdescription":"","description":"<a href='pages/data-analysis/DA0101EN-3-Review-Exploratory-Data-Analysis.ipynb' download>Download Sample Jupyter Notebook</a>","children":[{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis.Descriptive Statistics","name":"Descriptive Statistics","href":"#descriptive-statistics","type":"","shortdescription":"","description":"df.describe(): count, mean, std, min, 25%, 50%, 75%, max<br>value_counts(): drive_wheels_counts=df[\"drive-wheels\"].value_counts().to_frame()","children":[{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis.Descriptive Statistics.Box Plot","name":"Box Plot","href":"#box-plot","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ExploratoryDataAnalysis.DescriptiveStatistics.BoxPlot.jpg /><br>sns.boxplot(x=\"drive-wheels\", y=\"price\", data=df)","children":[]},{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis.Descriptive Statistics.Scatter Plot","name":"Scatter Plot","href":"#scatter-plot","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ExploratoryDataAnalysis.DescriptiveStatistics.ScatterPlot.jpg />","children":[]}]},{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis.GroupBy","name":"GroupBy","href":"#group-by","type":"","shortdescription":"","description":"df_test = df[['drive-wheels', 'body-style', 'price']]<br>df_grp = df_test(['drive-wheels', 'body-style'], as_index=False).mean()","children":[{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis.GroupBy.Pivot","name":"Pivot","href":"#pivot","type":"","shortdescription":"","description":"One variable displayed along the columns and the other variable displayed along the rows<br>Eg: drive wheels displayed along the columns and body style displayed along the rows<br>df_pivot = df_grp.pivot(index='drive-wheels', columns='body-style')","children":[]},{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis.GroupBy.Heatmap","name":"Heatmap","href":"#heatmap","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ExploratoryDataAnalysis.GroupBy.Heatmap.jpg />","children":[]}]},{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis.Correlation","name":"Correlation","href":"#correlation","type":"","shortdescription":"","description":"statistical metric for measuring to what extent different variables are interdependent. Or, if one variable changes, how does this affect change in the other variable","children":[{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis.Correlation.Pearson Correlation","name":"Pearson Correlation","href":"#pearson-correlation","type":"","shortdescription":"","description":"Measure the strength of the correlation between two features<br>- Correlation coefficient<br>- P-value<br><br>Correlation coefficient<br>- Close to +1: Large positive relationship<br>- Close to -1: Large negative relationship<br>- Close to 0: No relationship<br><br>P-value<br>- < 0.001 Strong certainty in the result<br>- < 0.05 Moderate certainty in the result<br>- < 0.1 Weak certainty in the result<br>- >0.1 No certainty in the result<br><br>pearson_coef, p_value = stats.pearsonr(df['horsepower'], df['price'])","children":[]},{"id":"Data Science.Data Analysis with Python.Exploratory Data Analysis.Correlation.ANOVA Analisis of Variance","name":"ANOVA Analisis of Variance","href":"#anova","type":"","shortdescription":"","description":"ANOVA can be used to find the correlation between different groups of a categorical variable. According to the car dataset, we can use ANOVA to see if there is any difference in mean price for the different car makes such a Subaru and Honda. The ANOVA test returns two values, the F-test score and the p-value. The F-test calculates the ratio of variation between groups mean, over the variation within each of the sample groups. The p-value shows whether the obtained result is statistically significant. The F-test calculates the ratio of variation between groups means over the variation within each of the sample group means.<br>df_anova=df[['make', 'price']]<br>grouped_anova=df_anova.groupby(['make'])<br>anova_results_l=stats.f_oneway(grouped_anova.get_group('honda')['price'], grouped_anova.get_group('subaru')['price'])<br>ANOVA results: F=0.19744, p=F_onewayResult(statistic=0.197), pvalue=0.66)","children":[]}]}]},{"id":"Data Science.Data Analysis with Python.Model Development","name":"Model Development","href":"#model-development","type":"","shortdescription":"","description":"<a href='pages/data-analysis/DA0101EN-4-Review-Model-Development.ipynb' download>Download Sample Jupyter Notebook</a>","children":[{"id":"Data Science.Data Analysis with Python.Model Development.Simple Linear Regression","name":"Simple Linear Regression","href":"#simple-linear-regression","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Data Analysis with Python.Model Development.Multiple Linear Regression","name":"Multiple Linear Regression","href":"#multiple-linear-regression","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Data Analysis with Python.Model Development.Evaluation using Visualization","name":"Evaluation using Visualization","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Data Analysis with Python.Model Development.Evaluation using Visualization.Regression Plot","name":"Regression Plot","href":"#regression-plot","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.Evaluation.RegressionPlot.jpg />","children":[]},{"id":"Data Science.Data Analysis with Python.Model Development.Evaluation using Visualization.Residual Plot","name":"Residual Plot","href":"#residual-plot","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.Evaluation.ResidualPlot.jpg />Subtracting the target value from the predicted value. Then plotting the value accordingly. We expect to see the results to have zero mean, distributed evenly around the x axis with similar variance. ","children":[]},{"id":"Data Science.Data Analysis with Python.Model Development.Evaluation using Visualization.Distribution Plot","name":"Distribution Plot","href":"#distribution-plot","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.Evaluation.DistributionPlot.jpg />","children":[]}]},{"id":"Data Science.Data Analysis with Python.Model Development.Polynomial Regression","name":"Polynomial Regression","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Data Analysis with Python.Model Development.Polynomial Regression.One Dimension","name":"One Dimension","href":"#polynomial-regression","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.PolynomialRegression.jpg />","children":[]},{"id":"Data Science.Data Analysis with Python.Model Development.Polynomial Regression.Many Dimensions","name":"Many Dimensions","href":"#polynomial-regression-many-dimensions","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.PolynomialRegressionManyDimensions.jpg />","children":[]}]},{"id":"Data Science.Data Analysis with Python.Model Development.Pipelines","name":"Pipelines","href":"#pipelines","type":"","shortdescription":"","description":"There are many steps to getting a prediction. For example, normalization, polynomial transform, and linear regression. We simplify the process using a pipeline. Pipeline sequentially perform a series of transformations. The last step carries out a prediction<br><img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.Pipelines.jpg />","children":[]},{"id":"Data Science.Data Analysis with Python.Model Development.Evaluation","name":"Evaluation","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Data Analysis with Python.Model Development.Evaluation.Mean Squared Error (MSE)","name":"Mean Squared Error (MSE)","href":"#mean-squared-error","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Data Analysis with Python.Model Development.Evaluation.R-squared/R^2/Coefficient of Determination","name":"R-squared/R^2/Coefficient of Determination","href":"#r-squared","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.Evaluation.RSquared.jpg /> Near one to be efficient","children":[]}]}]},{"id":"Data Science.Data Analysis with Python.Model Evaluation and Refinement","name":"Model Evaluation and Refinement","href":"#model-evaluation","type":"","shortdescription":"","description":"<a href='pages/data-analysis/DA0101EN-5-Review-Model-Evaluation-and-Refinement.ipynb' download>Download Sample Jupyter Notebook</a>","children":[{"id":"Data Science.Data Analysis with Python.Model Evaluation and Refinement.Cross Validation","name":"Cross Validation","href":"#cross-validation","type":"","shortdescription":"","description":"<img src=assets/images/data-science/DataScience.DataAnalysiswithPython.ModelEvaluation.CrossValidation.jpg /><br>The dataset is split into K equal groups. Each group is referred to as a fold. Some of the folds can be used as a training set which we use to train the model and the remaining parts are used as a test set, which we use to test the model. For example, we can use three folds for training, then use one fold for testing. This is repeated until each partition is used for both training and testing. At the end, we use the average results as the estimate of out-of-sample error.","children":[]},{"id":"Data Science.Data Analysis with Python.Model Evaluation and Refinement.Underfitting","name":"Underfitting","href":"#underfitting","type":"","shortdescription":"","description":"Where the model is too simple to fit the data. If we increase the order of the polynomial, the model fits better, but the model is still not flexible enough and exhibits underfitting.","children":[]},{"id":"Data Science.Data Analysis with Python.Model Evaluation and Refinement.Overfitting","name":"Overfitting","href":"#overfitting","type":"","shortdescription":"","description":"The model is too flexible and fits the noise rather than the function.","children":[]},{"id":"Data Science.Data Analysis with Python.Model Evaluation and Refinement.Ridge Regression","name":"Ridge Regression","href":"#ridge-regression","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelEvaluation.RidgeRegression.jpg />In many cases real data has outliers. This is especially evident for the higher order polynomials. Ridge regression controls the magnitude of these polynomial coefficients by introducing the parameter alpha. Alpha is a parameter we select before fitting or training the model. Each row in the following table represents an increasing value of alpha. <br>The column corresponds to the different polynomial coefficients, and the rows correspond to the different values of alpha. As alpha increases the parameters get smaller. This is most evident for the higher order polynomial features. But Alpha must be selected carefully. If alpha is too large, the coefficients will approach zero and underfit the data. If alpha is zero, the overfitting is evident. For alpha equal to 0.001, the overfitting begins to subside. For Alpha equal to 0.01, the estimated function tracks the actual function. When alpha equals one, we see the first signs of underfitting. The estimated function does not have enough flexibility. At alpha equals to 10, we see extreme underfitting. It does not even track the two points. In order to select alpha, we use cross validation.","children":[]},{"id":"Data Science.Data Analysis with Python.Model Evaluation and Refinement.Grid Search","name":"Grid Search","href":"#grid-search","type":"Algorithm","shortdescription":"","description":"Grid-search is used to find the optimal hyperparameters of a model which results in the most ‘accurate’ predictions.<br> <img src=assets/images/DataScience.DataAnalysiswithPython.ModelEvaluation.GridSearch.jpg /><br><img src=assets/images/data-science/DataScience.DataAnalysiswithPython.ModelEvaluation.GridSearch2.jpg /><br>A model hyperparameter is a characteristic of a model that is external to the model and whose value cannot be estimated from data. The value of the hyperparameter has to be set before the learning process begins. For example, c in Support Vector Machines, k in k-Nearest Neighbors, the number of hidden layers in Neural Networks.<br><br>In contrast, a parameter is an internal characteristic of the model and its value can be estimated from data. Example, beta coefficients of linear/logistic regression or support vectors in Support Vector Machines.","children":[]}]}]},{"id":"Data Science.Data Visualization with Python","name":"Data Visualization with Python","href":"#data-visualization","type":"","shortdescription":"","description":"<a href='pages/data-visualization/DV0101EN-1-1-1-Introduction-to-Matplotlib-and-Line-Plots-py-v2.0.ipynb' download>Download Sample Line Plots</a><br><a href='pages/data-visualization/DV0101EN-2-2-1-Area-Plots-Histograms-and-Bar-Charts-py-v2.0.ipynb' download>Download Sample Area Plots, Histograms and Bar Charts</a><br><a href='pages/data-visualization/DV0101EN-2-3-1-Pie-Charts-Box-Plots-Scatter-Plots-and-Bubble-Plots-py-v2.0.ipynb' download>Download Sample Pie Charts, Box Plots, Scatter Plots and Bubble Plots</a><br><a href='pages/data-visualization/DV0101EN-3-4-1-Waffle-Charts-Word-Clouds-and-Regression-Plots-py-v2.0.ipynb' download>Download Sample Waffle Charts, Word Clouds and Regression Plots</a><br><a href='pages/data-visualization/DV0101EN-3-5-1-Generating-Maps-in-Python-py-v2.0.ipynb' download>Download Sample Maps</a>","children":[{"id":"Data Science.Data Visualization with Python.Line Plots","name":"Line Plots","href":"#line-plots","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.LinePlots.jpg />","children":[]},{"id":"Data Science.Data Visualization with Python.Area Plots","name":"Area Plots","href":"#area-plots","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.AreaPlots.jpg />","children":[]},{"id":"Data Science.Data Visualization with Python.Histograms","name":"Histograms","href":"#histograms","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.Histograms.jpg />","children":[]},{"id":"Data Science.Data Visualization with Python.Bar Charts","name":"Bar Charts","href":"#bar-charts","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.BarCharts.jpg />","children":[]},{"id":"Data Science.Data Visualization with Python.Pie Charts","name":"Pie Charts","href":"#pie-charts","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.PieCharts.jpg />","children":[]},{"id":"Data Science.Data Visualization with Python.Box Plots","name":"Box Plots","href":"#box-plots","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.BoxPlots.jpg />","children":[]},{"id":"Data Science.Data Visualization with Python.Scatter Plots","name":"Scatter Plots","href":"#scatter-plots","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.ScatterPlots.jpg />","children":[]},{"id":"Data Science.Data Visualization with Python.Waffle Charts","name":"Waffle Charts","href":"#waffle-charts","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.WaffleCharts.jpg />Normally created to display progress toward goals","children":[]},{"id":"Data Science.Data Visualization with Python.Word Clouds","name":"Word Clouds","href":"#word-clouds","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.WordClouds.jpg />A Word cloud is a depiction of the frequency of different words in some textual data.","children":[]},{"id":"Data Science.Data Visualization with Python.Regression Plots","name":"Regression Plots","href":"#regression-plot","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.Evaluation.RegressionPlot.jpg />","children":[]},{"id":"Data Science.Data Visualization with Python.Maps with Folium","name":"Maps with Folium","href":"#maps-with-folium","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.MapsWithFolium.jpg />","children":[]},{"id":"Data Science.Data Visualization with Python.Choropleth Maps","name":"Choropleth Maps","href":"#choropleth-maps","type":"plots","shortdescription":"","description":"<img src=assets/images/DataScience.DataVisualizationwithPython.ChoroplethMaps.jpg />","children":[]}]},{"id":"Data Science.Machine Learning with Python","name":"Machine Learning with Python","href":"#machine-learning","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Techniques","name":"Techniques","href":"#machine-learning-techniques","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Techniques.Regression/Estimation","name":"Regression/Estimation","href":"#regression-estimation","type":"","shortdescription":"","description":"Predicting continuous values","children":[]},{"id":"Data Science.Machine Learning with Python.Techniques.Classification","name":"Classification","href":"#classification","type":"","shortdescription":"","description":"Predicting the item class/category of a case","children":[]},{"id":"Data Science.Machine Learning with Python.Techniques.Clustering","name":"Clustering","href":"#clustering","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Techniques.Associations","name":"Associations","href":"#associations","type":"","shortdescription":"","description":"Associating frequent co-occurring items/events","children":[]},{"id":"Data Science.Machine Learning with Python.Techniques.Anomaly detection","name":"Anomaly detection","href":"#anomaly-detection","type":"","shortdescription":"","description":"Discovering abnormal and unusual cases","children":[]},{"id":"Data Science.Machine Learning with Python.Techniques.Sequence mining","name":"Sequence mining","href":"#sequence-mining","type":"","shortdescription":"","description":"Predicting next events; click-stream (Markov Model, HMM)","children":[]},{"id":"Data Science.Machine Learning with Python.Techniques.Dimension Reduction","name":"Dimension Reduction","href":"#dimension-reduction","type":"","shortdescription":"","description":"Reducing the size of data","children":[{"id":"Data Science.Machine Learning with Python.Techniques.Dimension Reduction.Linear","name":"Linear","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Techniques.Dimension Reduction.Linear.Principle Component Analysis (PCA)","name":"Principle Component Analysis (PCA)","href":"#principle-component-analysis","type":"Method","shortdescription":"","description":"<img src=assets/images/data-science/DataScience.MachineLearningwithPython.Techniques.DemensionReduction.PCA.jpg /><br>Calculating PCA<br>1. Centre the data<br>- Compute covariance matrix<br>- Find the eigenvectors and eigen values of covariance matrix<br>2. The eigenvectors become the principal components<br>3. The eigenvalues provide the explained variance<br>4. Select new dimensions and project the data","children":[]},{"id":"Data Science.Machine Learning with Python.Techniques.Dimension Reduction.Linear.Linear Discriminant Analysis (LDA)","name":"Linear Discriminant Analysis (LDA)","href":"#","type":"Method","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Techniques.Dimension Reduction.Linear.Canonical correlation analysis","name":"Canonical correlation analysis","href":"#","type":"Method","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Techniques.Dimension Reduction.Linear.Multi-dimensional scaling","name":"Multi-dimensional scaling","href":"#","type":"Method","shortdescription":"","description":"","children":[]}]},{"id":"Data Science.Machine Learning with Python.Techniques.Dimension Reduction.Non-linear","name":"Non-linear","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Techniques.Dimension Reduction.Non-linear.Manifold learning (eg SOM, autoencoders etc)","name":"Manifold learning (eg SOM, autoencoders etc)","href":"#","type":"","shortdescription":"","description":"","children":[]}]}]},{"id":"Data Science.Machine Learning with Python.Techniques.Recommendation systems","name":"Recommendation systems","href":"#recommendation-systems","type":"","shortdescription":"","description":"Recommending items","children":[]}]},{"id":"Data Science.Machine Learning with Python.Supervised Learning","name":"Supervised Learning","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression","name":"Regression","href":"#supervised-regression","type":"","shortdescription":"","description":"Regression is the process of predicting a continuous value as opposed to predicting a categorical value in classification.","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Types","name":"Types","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Types.Simple Linear Regression","name":"Simple Linear Regression","href":"#simple-linear-regression","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.SimpleLinearRegression.jpg /><br><a href='pages/machine-learning/ML0101EN-Reg-Simple-Linear-Regression-Co2-py-v1-module-2.ipynb' download>Download Sample Jupyter Notebook</a>","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Types.Simple Non-linear Regression","name":"Simple Non-linear Regression","href":"#simple-nonlinear-regression","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-Reg-Polynomial-Regression-Co2-py-v1.ipynb' download>Download Sample Jupyter Notebook</a>","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Types.Multiple Linear Regression","name":"Multiple Linear Regression","href":"#multiple-linear-regression","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.DataAnalysiswithPython.ModelDevelopment.MultipleLinearRegression.jpg /><br><a href='pages/machine-learning/ML0101EN-Reg-Mulitple-Linear-Regression-Co2-py-v1-module-2.ipynb' download>Download Sample Jupyter Notebook</a>","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Types.Multiple Non-linear Regression","name":"Multiple Non-linear Regression","href":"#multiple-nonlinear-regression","type":"","shortdescription":"","description":"<br><a href='pages/machine-learning/ML0101EN-Reg-NoneLinearRegression-py-v1.ipynb' download>Download Sample Jupyter Notebook</a><br>Non-linear regressions are a relationship between independent variables  x  and a dependent variable  y  which result in a non-linear function modeled data. Essentially any relationship that is not linear can be termed as non-linear, and is usually represented by the polynomial of  k  degrees (maximum power of  x ).<br>Non-linear functions can have elements like exponentials, logarithms, fractions, and others.","children":[]}]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Applications","name":"Applications","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Applications.Sales forecasting","name":"Sales forecasting","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Applications.Satisfaction analysis","name":"Satisfaction analysis","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Applications.Price estimation","name":"Price estimation","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Applications.Employment income","name":"Employment income","href":"#","type":"","shortdescription":"","description":"","children":[]}]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms","name":"Algorithms","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms.Ordinal regression","name":"Ordinal regression","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms.Poisson regression","name":"Poisson regression","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms.Fast forest quantile regression","name":"Fast forest quantile regression","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms.Linear, Polynomial, Lasso, Stepwise, Ridge regression","name":"Linear, Polynomial, Lasso, Stepwise, Ridge regression","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms.Bayesian linear regression","name":"Bayesian linear regression","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms.Neural network regression","name":"Neural network regression","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms.Decision forest regression","name":"Decision forest regression","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms.Boosted decision tree regression","name":"Boosted decision tree regression","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Algorithms.KNN (K-nearest neighbors)","name":"KNN (K-nearest neighbors)","href":"#k-nearest-neighbor","type":"","shortdescription":"","description":"","children":[]}]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Regression.Evaluation Metrics","name":"Evaluation Metrics","href":"#regression-evaluation-metrics","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.SupervisedLearning.Regression.EvaluationMetrics.jpg />","children":[]}]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification","name":"Classification","href":"#supervised-classification","type":"","shortdescription":"","description":"Classification is the process of predicting a discrete class label, or category.","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Applications","name":"Applications","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Applications.Email filtering","name":"Email filtering","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Applications.Speech recognition","name":"Speech recognition","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Applications.Handwriting recognition","name":"Handwriting recognition","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Applications.Biometric identification","name":"Biometric identification","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Applications.Document classification","name":"Document classification","href":"#","type":"","shortdescription":"","description":"","children":[]}]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms","name":"Algorithms","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0)","name":"Decision Trees (ID3, C4 5, C5 0)","href":"#decision-tree","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-Clas-Decision-Trees-drug-py-v1.ipynb' download>Download Sample Jupyter Notebook</a><br>Algorithm: <br>- Choose an attribute from your dataset.<br>- Calculate the significance of attribute in splitting of data. <br>- Split data based on the value of the best attribute<br>- Go to step 1","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0).Building Decision Tree","name":"Building Decision Tree","href":"#building-decision-tree","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Classification.Algorithms.DecisionTrees.Building.jpg />","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0).Predictiveness","name":"Predictiveness","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0).Impurity","name":"Impurity","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0).Entropy","name":"Entropy","href":"#entropy","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Classification.Algorithms.DecisionTrees.Entropy.jpg />","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0).Information Gain","name":"Information Gain","href":"#information-gain","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Classification.Algorithms.DecisionTrees.InformationGain.jpg /><br>Information Gain is the information that can increase the level of certainty after splitting<br>Information Gain = (Entropy before split) - (weighted entropy after split)","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0).Random Forest","name":"Random Forest","href":"#random-forest","type":"Ensemble Learning Method","shortdescription":"","description":"<img src=assets/images/data-science/DataScience.MachineLearningWithPython.UnsupervisedLearning.Classification.Algorithms.DecisionTrees.RandomForest.png /><br>","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0).Random Forest.Bootstrap Aggregation (Bagging)","name":"Bootstrap Aggregation (Bagging)","href":"#bagging","type":"Technique","shortdescription":"","description":"The training algorithm for random forests applies the general technique of bootstrap aggregating, or bagging, to tree learners. Given a training set X = x1, ..., xn with responses Y = y1, ..., yn, bagging repeatedly (B times) selects a random sample with replacement of the training set and fits trees to these samples:<br><img src=assets/images/data-science/DataScience.MachineLearningWithPython.UnsupervisedLearning.Classification.Algorithms.DecisionTrees.RandomForest.Bagging.jpg /><br>","children":[]}]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0).Gradient Boosted Trees","name":"Gradient Boosted Trees","href":"#gradient-boosted-trees","type":"Ensemble Learning Method","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Decision Trees (ID3, C4 5, C5 0).Gradient Boosted Trees.Boosting","name":"Boosting","href":"#boosting","type":"Technique","shortdescription":"","description":"","children":[]}]}]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Naive Bayes","name":"Naive Bayes","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Linear Discriminant Analysis","name":"Linear Discriminant Analysis","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.k-Nearest Neighbor","name":"k-Nearest Neighbor","href":"#k-nearest-neighbor","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-Clas-K-Nearest-neighbors-CustCat-py-v1.ipynb' download>Download Sample Jupyter Notebook</a><br><img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Classification.Algorithms.KNN.png /><br>Algorithm<br>- Pick a value for K<br>- Calculate the distance of unknown case from all cases.<br>- Select the K-observations in the training data that are nearest to the unknown data point<br>- Predict the response of the unknown data point using the most popular response value from the K-nearest neighbors.","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Logistic Regression","name":"Logistic Regression","href":"#logistic-regression","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-Clas-Logistic-Reg-churn-py-v1.ipynb' download>Download Sample Jupyter Notebook</a><br><img src=assets/images/data-science/DataScience.MachineLearningWithPython.SupervisedLearning.Classification.Algorithms.LogisticRegression.jpg />","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Neural Networks","name":"Neural Networks","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Support Vector Machines (SVM)","name":"Support Vector Machines (SVM)","href":"#support-vector-machines","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-Clas-SVM-cancer-py-v1.ipynb' download>Download Sample Jupyter Notebook</a><br>SVM is a supervised algorithm that classifies cases by finding a separator. <br>- Mapping data to a high-dimensional feature space<br>- Finding a separator<br><img src=assets/images/DataScience.MachineLearningWithPython.SupervisedLearning.Classification.Algorithms.SupportVectorMachine.jpg /><br><img src=assets/images/DataScience.MachineLearningWithPython.SupervisedLearning.Classification.Algorithms.SupportVectorMachineDataTransformation.jpg /><br>Applications: <br>- Image recognition<br>- Text category assignment<br>- Detecting spam<br>- Sentiment analysis<br>- Gene Expression Classification<br>- Regression, outlier detection and clustering","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Algorithms.Support Vector Machines (SVM).Kernelling","name":"Kernelling","href":"#kernelling","type":"","shortdescription":"","description":"Mapping data into a higher-dimensional space. The mathematical function used for the transformation is known as the kernel function, and can be of different types, such as: <br>- Linear<br>- Polynomial<br>- Radial Basis Function (RBF)<br>- Sigmoid.","children":[]}]}]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Evaluation metrics","name":"Evaluation metrics","href":"#classification-evaluation-metrics","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Evaluation metrics.Jaccard index","name":"Jaccard index","href":"#jaccard-index","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Classification.EvaluationMetrics.JaccardIndex.jpg />","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Evaluation metrics.F1 Score","name":"F1 Score","href":"#f1-score","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Classification.EvaluationMetrics.F1Score.jpg />","children":[]},{"id":"Data Science.Machine Learning with Python.Supervised Learning.Classification.Evaluation metrics.Log Loss","name":"Log Loss","href":"#log-loss","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Classification.EvaluationMetrics.LogLoss.jpg /><br>Near 0 -> Higher accuracy","children":[]}]}]}]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning","name":"Unsupervised Learning","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Dimension reduction","name":"Dimension reduction","href":"#dimension-reduction","type":"","shortdescription":"","description":"Dimensionality reduction, and/or feature selection, play a large role in this by reducing redundant features to make the classification easier.","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Density estimation","name":"Density estimation","href":"#density-estimation","type":"","shortdescription":"","description":"Density estimation is a very simple concept that is mostly used to explore the data to find some structure within it.","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Market basket analysis","name":"Market basket analysis","href":"#market-basket-analysis","type":"","shortdescription":"","description":"Market basket analysis is a modeling technique based upon the theory that if you buy a certain group of items, you're more likely to buy another group of items.","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering","name":"Clustering","href":"#clustering","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Clustering.jpg /><br>Clustering is grouping of data points or objects that are somehow similar by: <br>- Discovering structure<br>- Summarization<br>- Anomaly detection","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications","name":"Applications","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Retail/Marketing: Identify buying patterns of customers","name":"Retail/Marketing: Identify buying patterns of customers","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Retail/Marketing: Recommending new books or movies to new customers","name":"Retail/Marketing: Recommending new books or movies to new customers","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Banking: Fraud detection in credit card use","name":"Banking: Fraud detection in credit card use","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Banking: Identifying clusters of customers (eg: loyal)","name":"Banking: Identifying clusters of customers (eg: loyal)","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Insurance: Fraud detection in claims analysis","name":"Insurance: Fraud detection in claims analysis","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Insurance: Insurance risk of customers","name":"Insurance: Insurance risk of customers","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Publication: Auto-categorizing news based on their content","name":"Publication: Auto-categorizing news based on their content","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Publication: Recommending similar news articles","name":"Publication: Recommending similar news articles","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Medicine: Characterizing patient behavior","name":"Medicine: Characterizing patient behavior","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Applications.Biology: Clustering genetic markers to identify family ties","name":"Biology: Clustering genetic markers to identify family ties","href":"#","type":"","shortdescription":"","description":"","children":[]}]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms","name":"Algorithms","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Partitioned-based Clustering","name":"Partitioned-based Clustering","href":"#partition-based-clustering","type":"","shortdescription":"","description":"Relatively efficient<br>E.g. k-Means, k-Median, Fuzzy c-Means","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Partitioned-based Clustering.k-Means Clustering","name":"k-Means Clustering","href":"#k-means-clustering","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-Clus-K-Means-Customer-Seg-module-4.ipynb' download>Download Sample Jupyter Notebook</a><br>1. Initialize k=(number of clusters) centroids randomly<br>2. Calculate the distance of each point from each centroid<br>3. Assign each data point (object) to its closest centroid, creating a cluster<br>4. Recalculate the position of the k centroids<br>5. Repeat until there are no more changes => Converged<br><img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Clustering.k-means-clustering.jpg />","children":[]}]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering","name":"Hierarchical Clustering","href":"#hierarchical-clustering","type":"","shortdescription":"","description":"Build a hierarchy of clusters where each node is a cluster consists of the clusters of its daughter nodes<br>Produces trees of clusters<br>E.g. Agglomerative, Divisive<br><br>Top-down: divisive; Bottom-Up: agglomerative<br><img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Clustering.HierarchicalClustering.jpg />","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Agglomerative Clustering","name":"Agglomerative Clustering","href":"#agglomerative-clustering","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-Clus-Hierarchical-Cars-py-v1-module-4.ipynb' download>Download Sample Jupyter Notebook</a><br>1. Create n clusters, one for each data point<br>2. Compute the Proximity Matrix (distance between each clusters)<br>3. Select two closest clusters according to distance between each pair of points (distance measurement can either be Euclidean, Pearson, average distance or many others depending on data type and domain knowledge)<br>4. Merge two closest clusters into one cluster and calculate the distance between the new cluster (center of two cluster) to other clusters<br>5. Repeat step 3 until only a single cluster remains<br><img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Clustering.AgglomerativeClustering.jpg />","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Distance between clusters","name":"Distance between clusters","href":"#distance-between-clusters","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Clustering.HierarchicalClustering.DistanceBetweenClusters.jpg />","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Distance between clusters.Single-Linkage Clustering","name":"Single-Linkage Clustering","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Distance between clusters.Complete-Linkage Clustering","name":"Complete-Linkage Clustering","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Distance between clusters.Average-Linkage Clustering","name":"Average-Linkage Clustering","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Distance between clusters.Centroid-Linkage Clustering","name":"Centroid-Linkage Clustering","href":"#","type":"","shortdescription":"","description":"","children":[]}]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Distance measurement","name":"Distance measurement","href":"#distance-measurement","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Distance measurement.Euclidean","name":"Euclidean","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Distance measurement.Pearson","name":"Pearson","href":"#","type":"","shortdescription":"","description":"","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Hierarchical Clustering.Distance measurement.Average distance","name":"Average distance","href":"#","type":"","shortdescription":"","description":"","children":[]}]}]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Density-based Clustering","name":"Density-based Clustering","href":"#density-based-clustering","type":"","shortdescription":"","description":"Produces arbitrary shaped clusters<br>E.g. DBSCAN","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Density-based Clustering.DBSCAN Clustering","name":"DBSCAN Clustering","href":"#dbscan-clustering","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-Clus-DBSCN-weather-py-v1-module-4.ipynb' download>Download Sample Jupyter Notebook</a><br>Density-Based Spatial Clustering of Applications with Noise<br>R (Radius of neighborhood) that if includes enough number of points within, we call it a dense area<br>M (Min number of neighbors) The minimum number of data points we want in a neighborhood to define a cluster<br><br>Let's pick a point randomly. First, we check to see whether it's a core data point.<br> A data point is a core point if within neighborhood of the point there are at least M points. <br>For example, as there are six points in the two centimeter neighbor of the red point, we mark this point as a core point. <br>A data point is a border point if A; its neighbourhood contains less than M data points or B; it is reachable from some core point. <br>Here, reachability means it is within our distance from a core point. It means that even though the yellow point is within the two centimeter neighborhood of the red point, it is not by itself a core point because it does not have at least six points in its neighborhood. <br>The grey point is not a core point nor is it a border point. So, we'd label it as an outlier. An outlier is a point that is not a core point and also is not close enough to be reachable from a core point. We continue and visit all the points in the dataset and label them as either core, border, or outlier. <br>The next step is to connect core points that are neighbors and put them in the same cluster. So, a cluster is formed as at least one core point plus all reachable core points plus all their borders. It's simply shapes all the clusters and finds outliers as well.<br><img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Clustering.DensityBasedClustering.DBSCAN.jpg />","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Density-based Clustering.Types","name":"Types","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Density-based Clustering.Types.Spherical-shape clusters","name":"Spherical-shape clusters","href":"#spherical-shape-clusters","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Clustering.DensityBasedClustering.SphericalShapeCluster.jpg />","children":[]},{"id":"Data Science.Machine Learning with Python.Unsupervised Learning.Clustering.Algorithms.Density-based Clustering.Types.Arbitrary-shape clusters","name":"Arbitrary-shape clusters","href":"#arbitrary-shape-clusters","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.UnsupervisedLearning.Clustering.DensityBasedClustering.ArbitraryShapeCluster.jpg />","children":[]}]}]}]}]}]},{"id":"Data Science.Machine Learning with Python.Recommendation System","name":"Recommendation System","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Recommendation System.Applications","name":"Applications","href":"#recommendation-system-applications","type":"","shortdescription":"","description":"Where to buy? E-commerce, books, movies, beer, shoes<br>Where to eat?<br>Which job to apply to?<br>Who you should be friends with?<br>Personalize your experience on the web: News platforms, news personalization","children":[]},{"id":"Data Science.Machine Learning with Python.Recommendation System.Types","name":"Types","href":"#recommendation-system-types","type":"","shortdescription":"","description":"<img src=assets/images/DataScience.MachineLearningWithPython.RecommendationSystem.Types.jpg />","children":[{"id":"Data Science.Machine Learning with Python.Recommendation System.Types.Content-Based","name":"Content-Based","href":"#content-based","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-RecSys-Content-Based-movies-py-v1-module-5.ipynb' download>Download Sample Jupyter Notebook</a><br>Similar items","children":[]},{"id":"Data Science.Machine Learning with Python.Recommendation System.Types.Collaborative Filtering","name":"Collaborative Filtering","href":"#collaborative-filtering","type":"","shortdescription":"","description":"<a href='pages/machine-learning/ML0101EN-RecSys-Collaborative-Filtering-movies-py-v1-module-5.ipynb' download>Download Sample Jupyter Notebook</a><br>Similar preferences<br><img src=assets/images/DataScience.MachineLearningWithPython.RecommendationSystem.Types.CollaborativeFiltering.jpg />","children":[{"id":"Data Science.Machine Learning with Python.Recommendation System.Types.Collaborative Filtering.User-based","name":"User-based","href":"#user-based","type":"","shortdescription":"","description":"Based on users' neighborhood","children":[]},{"id":"Data Science.Machine Learning with Python.Recommendation System.Types.Collaborative Filtering.Item-based","name":"Item-based","href":"#item-based","type":"","shortdescription":"","description":"Based on items' similarity","children":[]},{"id":"Data Science.Machine Learning with Python.Recommendation System.Types.Collaborative Filtering.Challenges","name":"Challenges","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Recommendation System.Types.Collaborative Filtering.Challenges.Data Sparsity","name":"Data Sparsity","href":"#data-sparsity","type":"","shortdescription":"","description":"Users in general rate only a limited number of items","children":[]},{"id":"Data Science.Machine Learning with Python.Recommendation System.Types.Collaborative Filtering.Challenges.Cold start","name":"Cold start","href":"#cold-start","type":"","shortdescription":"","description":"Difficulty in recommendation to new users or new items","children":[]},{"id":"Data Science.Machine Learning with Python.Recommendation System.Types.Collaborative Filtering.Challenges.Scalability","name":"Scalability","href":"#scalability","type":"","shortdescription":"","description":"Increase in number of users or items","children":[]}]}]}]},{"id":"Data Science.Machine Learning with Python.Recommendation System.Implementing","name":"Implementing","href":"#","type":"","shortdescription":"","description":"","children":[{"id":"Data Science.Machine Learning with Python.Recommendation System.Implementing.Memory-based","name":"Memory-based","href":"#memory-based","type":"","shortdescription":"","description":"Uses the entire user-item dataset to generate a recommendation<br>Uses statistical techniques to approximate users or items e.g., Pearson Correlation, Cosine Similarity, Euclidean Distance, etc.","children":[]},{"id":"Data Science.Machine Learning with Python.Recommendation System.Implementing.Model-based","name":"Model-based","href":"#model-based","type":"","shortdescription":"","description":"Develops a model of users in an attempt to learn their preferences<br>Models can be created using Machine Learning techniques like regression, clustering, classification, etc. ","children":[]}]}]}]}]}]